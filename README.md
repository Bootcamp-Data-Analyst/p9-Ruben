#  Unsupervised Learning Workshop ‚Äì Mushroom Dataset

##  Descripci√≥n del Proyecto

Este proyecto desarrolla un flujo completo de an√°lisis y modelado sobre el **Mushroom Dataset** del UCI Repository, con el objetivo de:

- Transformar un dataset categ√≥rico complejo en una matriz apta para modelado.
- Analizar patrones estructurales mediante t√©cnicas estad√≠sticas y visuales.
- Aplicar **reducci√≥n de dimensionalidad (PCA)**.
- Detectar estructuras latentes con **K-Means Clustering**.
- Comparar los resultados de aprendizaje no supervisado con un modelo supervisado (**Random Forest**).

El proyecto est√° estructurado en tres notebooks independientes que siguen un pipeline l√≥gico:

1. Limpieza y transformaci√≥n  
2. An√°lisis exploratorio (EDA)  
3. Modelado y comparaci√≥n  

---

#  Dataset

üîó UCI Mushroom Dataset  

- Cada fila representa un hongo.  
- Todas las variables son categ√≥ricas nominales.  
- Variable objetivo:  
  - `e` ‚Üí edible  
  - `p` ‚Üí poisonous  

---

#  Estructura del Proyecto

| Archivo | Descripci√≥n |
|----------|-------------|
| `cleaning.ipynb` | Limpieza, tipado y transformaci√≥n inicial del dataset |
| `eda.ipynb` | An√°lisis exploratorio univariado, bivariado y multivariado |
| `machine_learning.ipynb` | Modelado con PCA, KMeans y Random Forest |
| `data/clean/agaricus-lepiota` | Dataset limpio exportado |

---

# 1Ô∏è Limpieza y Transformaci√≥n (`cleaning.ipynb`)

##  Carga y estructuraci√≥n

- Asignaci√≥n manual de nombres de columnas seg√∫n documentaci√≥n oficial.
- Conversi√≥n de variables a tipo `category`.
- Mapeo sem√°ntico de valores (ej. `p` ‚Üí poisonous).

##  Limpieza aplicada

- Eliminaci√≥n de columna constante (`veil-type`).
- Detecci√≥n y an√°lisis de valores nulos.
- Imputaci√≥n de valores faltantes en `stalk-root` usando la moda.
- Validaci√≥n de unicidad y estructura final.

##  Exportaci√≥n

El dataset limpio se exporta para su uso posterior en formato parquet.

---

# 2Ô∏è An√°lisis Exploratorio (EDA) (`eda.ipynb`)

El EDA se desarrolla en tres niveles:

##  An√°lisis Univariado

- Distribuci√≥n de la variable objetivo.
- Conteo de categor√≠as por variable.
- Identificaci√≥n de dominancias y posibles sesgos.

##  An√°lisis Bivariado

- Comparaci√≥n de cada variable respecto a la clase (edible vs poisonous).
- Visualizaci√≥n de proporciones.
- Identificaci√≥n de variables con alta capacidad discriminatoria.

##  An√°lisis Multivariado

- Test Chi-cuadrado para medir asociaci√≥n entre variables y la clase.
- Ranking de fuerza estad√≠stica.
- Identificaci√≥n de predictores clave (ej. `odor`).

###  Hallazgos principales

- Algunas variables muestran una separaci√≥n casi determinista entre clases.
- El olor aparece como uno de los predictores m√°s fuertes.
- Las combinaciones de variables mejoran la discriminaci√≥n frente a variables aisladas.

---

# 3Ô∏è Modelado y Machine Learning (`machine_learning.ipynb`)

##  Preprocesado

- Conversi√≥n de variable objetivo a formato binario (LabelEncoder).
- One-Hot Encoding sobre variables categ√≥ricas.
- Separaci√≥n en `X` e `y`.
- Divisi√≥n en train/test (80/20).
- Uso consistente de `random_state=42`.

---

##  PCA ‚Äì Reducci√≥n de Dimensionalidad

- Aplicaci√≥n de PCA para visualizaci√≥n en 2 componentes.
- Evaluaci√≥n del impacto del n√∫mero de componentes en rendimiento.
- Estudio del trade-off entre dimensionalidad y accuracy.
- An√°lisis del rendimiento del modelo con distintos n√∫meros de componentes (2 a 28).

---

##  Random Forest (Modelo Supervisado)

- Entrenamiento con todas las features codificadas.
- Evaluaci√≥n de accuracy.
- Comparaci√≥n:
  - Random Forest sin PCA.
  - Random Forest con PCA reducido.

###  Objetivo

Determinar si la reducci√≥n de dimensionalidad mantiene la se√±al predictiva sin degradar el rendimiento.

---

##  Clustering con K-Means (No Supervisado)

- Determinaci√≥n del n√∫mero √≥ptimo de clusters.
- Entrenamiento con:
  - Features originales.
  - Features reducidas por PCA.
- Visualizaci√≥n de clusters en 2D.
- Comparaci√≥n entre clusters y clases reales (sin usar etiquetas durante entrenamiento).

###  Evaluaci√≥n conceptual

Se analiza la correspondencia entre clusters y etiquetas reales para evaluar:

- Si la estructura natural del dataset separa correctamente setas comestibles y venenosas.
- Si el problema puede abordarse desde segmentaci√≥n no supervisada.

---

#  Comparativa Final

| Modelo | Tipo | Uso de PCA | Objetivo |
|--------|------|------------|----------|
| Random Forest | Supervisado | No | L√≠nea base |
| Random Forest | Supervisado | S√≠ | Evaluar reducci√≥n |
| K-Means | No supervisado | S√≠/No | Descubrir estructura latente |

---

#  Conclusiones

- El dataset presenta variables con alta capacidad discriminatoria.
- La reducci√≥n con PCA permite compresi√≥n significativa manteniendo rendimiento.
- El clustering muestra estructuras que parcialmente coinciden con las clases reales.
- El aprendizaje no supervisado puede aproximarse al problema, pero el modelo supervisado ofrece mayor precisi√≥n.

Este proyecto demuestra:

- Dominio del flujo completo de Data Science.
- Gesti√≥n avanzada de variables categ√≥ricas.
- Aplicaci√≥n combinada de t√©cnicas supervisadas y no supervisadas.
- Capacidad de an√°lisis estad√≠stico e interpretaci√≥n de resultados.

---

#  Tecnolog√≠as Utilizadas

- Python 3.10+
- Pandas
- NumPy
- Matplotlib
- Seaborn
- Scikit-learn:
  - PCA
  - KMeans
  - RandomForestClassifier
  - Train/Test Split
  - OneHotEncoder
  - LabelEncoder

---

#  Instalaci√≥n y Ejecuci√≥n

```bash
python -m venv .venv
.venv\Scripts\activate
pip install -r requirements.txt
jupyter notebook
